{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from utils import autoparse_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = pd.read_csv(\n",
    "\t'../data/raw/MovieSummaries/plot_summaries.txt',\n",
    "\tsep='\\t',\n",
    "\t# index_col='wiki_id',\n",
    "\tnames=['wiki_id', 'summary'],\n",
    "\tdtype={'summary': pd.StringDtype()}\n",
    ")\n",
    "assert df_summary.index.is_unique\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary.to_pickle('../data/generated/preprocessed/summary.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv(\n",
    "\t'../data/raw/MovieSummaries/movie.metadata.tsv', sep='\\t',\n",
    "\t# index_col='wiki_id',\n",
    "\tnames=['wiki_id', 'fb_id', 'movie_name', 'movie_release', 'movie_revenue', 'movie_runtime', 'movie_languages', 'movie_countries', 'movie_genres']\n",
    ")\n",
    "# unwrap the mappings\n",
    "df_movies.movie_languages = df_movies.movie_languages.map(lambda x: list(json.loads(x).values()))[0][0]\n",
    "df_movies.movie_countries = df_movies.movie_countries.map(lambda x: list(json.loads(x).values()))[0][0]\n",
    "df_movies.movie_genres = df_movies.movie_genres.map(lambda x: list(json.loads(x).values()))[0][0]\n",
    "df_movies['movie_release_year'] = df_movies.movie_release.apply(autoparse_year).astype('Int64')\n",
    "# TODO : convert dates to months also, where applicable\n",
    "\n",
    "assert df_movies.index.is_unique\n",
    "df_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correcting some anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies[df_movies.movie_release_year == 1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.loc[df_movies.movie_release_year == 1010, 'movie_release'] = '2010-12-02'\n",
    "df_movies.loc[df_movies.movie_release_year == 1010, 'movie_release_year'] = 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.to_pickle('../data/generated/preprocessed/movies.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chars = pd.read_csv(\n",
    "\t'../data/raw/MovieSummaries/character.metadata.tsv', sep='\\t',\n",
    "\tnames=['wiki_id', 'fb_movie_id', 'release', 'character_name', 'actor_birth', 'actor_gender', 'actor_height', 'ethnicity', 'actor_name', 'actor_age', 'fb_char_id', 'useless_fb_char_id', 'fb_actor_id'],\n",
    ")\n",
    "df_chars = df_chars.drop(\"useless_fb_char_id\", axis=1)\n",
    "assert df_chars.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actor2nationality_id = pd.read_csv(\"../data/raw/extra/actor_id2nationality_id.csv\", skiprows=1, names=[\"fb_actor_id\", \"nationality_id\"])\n",
    "df_nationality_id2nationality = pd.read_csv(\"../data/raw/extra/nationality_id2nationality.csv\", skiprows=1, names=[\"nationality_id\", \"actor_nationality\"])\n",
    "df_nationality = pd.merge(df_actor2nationality_id, df_nationality_id2nationality, on=\"nationality_id\")\n",
    "df_nationality = df_nationality.drop(\"nationality_id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nationality = df_nationality.drop_duplicates(subset=[\"fb_actor_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chars = pd.merge(df_chars, df_nationality, on=\"fb_actor_id\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chars.actor_nationality.count()\n",
    "with_nationnalities = df_chars.actor_nationality.count()\n",
    "ratio = 100.0 - 100.0*(with_nationnalities/len(df_chars))\n",
    "print(\"There are %d rows with resolved nationalities, this is %.01f%% of rows\"%(with_nationnalities, ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ethnic groups mapping (queried from wikidata)\n",
    "ethnic_groups = pd.read_csv('../data/raw/extra/ethnic_groups.csv', index_col=\"freebaseID\")\n",
    "found_ethnicities = pd.merge(df_chars, ethnic_groups, how=\"left\", left_on=\"ethnicity\", right_on=\"freebaseID\")\n",
    "now_count = found_ethnicities.name.count()\n",
    "previous_count = df_chars.ethnicity.count()\n",
    "ratio = 100.0 - 100.0*(now_count/previous_count)\n",
    "print(\"There were %d rows with ethnicities, and we can resolve %d of them. We lost %.1f%% of rows\"% (previous_count, now_count, ratio))\n",
    "\n",
    "dictionnary = {}\n",
    "for fbID, name in ethnic_groups.name.iteritems():\n",
    "    dictionnary[fbID] = name\n",
    "\n",
    "df_chars.ethnicity = df_chars.ethnicity.map(dictionnary)\n",
    "df_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chars.to_pickle('../data/generated/preprocessed/characters.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TV tropes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tropes = pd.read_csv(\n",
    "\t'../data/raw/MovieSummaries/tvtropes.clusters.txt',\n",
    "\tsep='\\t',\n",
    "\tnames=['trope', 'char_movie_id']\n",
    ")\n",
    "df_tropes['char_name'] = df_tropes.char_movie_id.map(lambda x: json.loads(x)['char'])\n",
    "df_tropes['movie_name'] = df_tropes.char_movie_id.map(lambda x: json.loads(x)['movie'])\n",
    "df_tropes['actor_name'] = df_tropes.char_movie_id.map(lambda x: json.loads(x)['actor'])\n",
    "df_tropes['fb_id'] = df_tropes.char_movie_id.map(lambda x: json.loads(x)['id'])\n",
    "df_tropes.drop(columns='char_movie_id', inplace=True)\n",
    "df_tropes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tropes.to_pickle('../data/generated/preprocessed/tropes.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_charclusters = pd.read_csv(\n",
    "\t'../data/raw/MovieSummaries/name.clusters.txt',\n",
    "\tsep='\\t',\n",
    "\tnames=['char_name', 'fb_id']\n",
    ")\n",
    "df_charclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_charclusters.to_pickle('../data/generated/preprocessed/character_clusters.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad5b998808e141dcf219506db0865f92fc9daa9e9e73c60e8d74e18645db35b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
